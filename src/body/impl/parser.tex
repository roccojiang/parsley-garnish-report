\documentclass[../../../main.tex]{subfiles}

\begin{document}

\section{Simplifying Parsers}\label{sec:simplify-parsers}

Reusing a similar abstract syntax representation as \texttt{parsley} itself unlocks some interesting insights for \texttt{parsley-garnish}.
\textcite{gibbons_dsls_2014} note that a deep-embedded \textsc{dsl} consists of two components:
\begin{enumerate}
  \item A representation of the language's abstract \emph{syntax}, in the form of the aforementioned datatype.
  \item Some traversals over the datatype, which gives \emph{semantics} to that syntax.
\end{enumerate}
%
A deep-embedded \textsc{dsl} and a linter for that \textsc{dsl} can thus be viewed as two different semantic interpretations over the same abstract syntax:
\begin{itemize}
  \item The \textsc{dsl} semantics are \emph{evaluation}. The syntactic structure may be transformed for optimisation purposes before generating code to be evaluated. % For \texttt{parsley}, the evaluation produces an optimised parser.
  \item The linter's semantics are two-fold for lint diagnostics and code rewrites:
  \begin{itemize}
    \item \emph{Emitting side-effects} as diagnostics, based on patterns of interest within the syntactic structure.
    \item \emph{Pretty-printing} a transformation over the syntactic structure, as a rewrite action -- crucially, unlike evaluation, the transformed output is not converted into code but rather a textual representation to be rewritten over the original source file. The output of this transformation may benefit from \emph{the same optimisation transformations as with the \textsc{dsl} semantics} to simplify the pretty-printed textual output.
  \end{itemize}
\end{itemize}
%
This \namecref{sec:simplify-parsers} shows that this is indeed the case for \texttt{parsley-garnish}:
the same optimisation transformations apply for both \texttt{parsley} (the \textsc{dsl}) and \texttt{parsley-garnish} (the linter).
The only difference lies in the purpose of performing these transformations:
\begin{itemize}
  \item \texttt{parsley-garnish} needs to perform simplifications on the \scala{Parser} \textsc{ast} to produce output of hand-written quality, or else the resulting parser would be unreadable, as was the case in \cref{fig:leftrec-example-bad}.
  \item \texttt{parsley} performs simplifications on its combinator tree to produce output of hand-written quality, in order to deliver excellent parser performance.
\end{itemize}

\subsection{Parser Laws}
\textcite{willis_parsley_2024} notes that parser combinators are subject to \emph{parser laws}, which often form a natural simplification in one direction.
Both \texttt{parsley} Scala~\cite{willis_garnishing_2018} and \texttt{parsley} Haskell~\cite{willis_staged_2023,willis_parsley_2024} use these laws as the basis for high-level optimisations to simplify the structure of deeply-embedded parsers.
These same principles are used by \texttt{parsley-garnish} to simplify parser terms to resemble the natural style that a human would write by hand.

\Cref{fig:parser-laws} shows the subset of parser laws utilised by \texttt{parsley-garnish} for parser simplification.
Most of these laws have already been shown to hold for Parsley by \textcite{willis_garnishing_2018}; an additional proof for \cref{eqn:alt-fmap-absorb} can be found in \cref{appendix:parser-law-proofs}.

\begin{figure}[htbp]
\centering
\begin{gather}
  % Functor
  \text{\scala{p.map(f).map(g) = p.map(g compose f)}} \label{eqn:functor-comp} \\
  % Applicative functor
  \text{\scala{pure(f) <*> pure(x) = pure(f(x))}} \label{eqn:app-homomorphism} \\
  \text{\scala{pure(f) <*> x = x.map(f)}} \label{eqn:app-fmap} \\
  % Alternative applicative functor
  \text{\scala{empty | u = u}} \label{eqn:alt-left-neutral} \\
  \text{\scala{u | empty = u}} \label{eqn:alt-right-neutral} \\
  \text{\scala{pure(x) | u = pure(x)}} \label{eqn:alt-left-biased-choice} \\
  \text{\scala{empty <*> u = empty}} \label{eqn:alt-empty-absorb} \\
  \text{\scala{empty.map(f) = empty}} \label{eqn:alt-fmap-absorb}
\end{gather}
% I wanted more fine-grained control, so instead of using \cleveref I have manually written out the references -- TAKE CARE to keep them in the same order as the equations
% \caption{Functor~\cref{eqn:functor-comp}, Applicative~\cref{eqn:app-homomorphism,eqn:app-fmap}, and Alternative~\cref{eqn:alt-left-neutral,eqn:alt-right-neutral,eqn:alt-left-biased-choice,eqn:alt-empty-absorb,eqn:alt-fmap-absorb} laws.}
\caption{Functor~(\ref{eqn:functor-comp}), Applicative~(\ref{eqn:app-homomorphism}, \ref{eqn:app-fmap}), and Alternative~(\ref{eqn:alt-left-neutral}--\ref{eqn:alt-fmap-absorb}) laws.}
\label{fig:parser-laws}
\end{figure}

\subsubsection{Simplifying the Example Parser}\label{sec:simplify-example}
It is useful to illustrate how these laws are used to simplify a parser term, by starting with the parser in \cref{fig:leftrec-example-bad}.
In the following example, function terms will be greyed out as they are still currently uninspectable -- this is work that is addressed in the next \namecref{sec:simplify-exprs}.

First of all, most of the noise in \scala{example} comes from the large number of \scala{empty} combinators.
These can be eliminated using \cref{eqn:alt-left-neutral,eqn:alt-right-neutral,eqn:alt-empty-absorb,eqn:alt-fmap-absorb}:
% lazy val example: Parsley[String] = chain.postfix(string("b"))(
%   (pure(identity).map(compose((_ + _).curried))).map(flip) <*> string("a")
% )
\begin{minted}[escapeinside=\%\%]{scala}
lazy val example: Parsley[String] = chain.postfix(string("b"))(
  (pure(%\textcolor{gray}{identity}%).map(%\textcolor{gray}{compose((\_ + \_).curried)}%)).map(%\textcolor{gray}{flip}%) <*> string("a")
)
\end{minted}
%
This already looks a lot better, but the second parameter to \scala{postfix} can be further simplified as follows:
% (pure(identity).map(compose((_ + _).curried))).map(flip) <*> string("a")
% pure(compose((_ + _).curried)(identity)).map(flip) <*> string("a")
% pure(flip(compose((_ + _).curried)(identity))) <*> string("a")
% string("a").map(flip(compose((_ + _).curried)(identity)))
\begin{minted}[baselinestretch=1.5,escapeinside=\%\%]{scala}
    (pure(%\textcolor{gray}{identity}%).map(%\textcolor{gray}{compose((\_ + \_).curried)}%)).map(%\textcolor{gray}{flip}%) <*> string("a")
% \proofstep{\cref{eqn:app-homomorphism,eqn:app-fmap}} %
    pure(%\textcolor{gray}{compose((\_ + \_).curried)(identity)}%).map(%\textcolor{gray}{flip}%) <*> string("a")
% \proofstep{\cref{eqn:app-homomorphism,eqn:app-fmap}} %
    pure(%\textcolor{gray}{flip(compose((\_ + \_).curried)(identity))}%) <*> string("a")
% \proofstep{\cref{eqn:app-fmap}} %
    string("a").map(%\textcolor{gray}{flip(compose((\_ + \_).curried)(identity))}%)
\end{minted}
%
The final simplified form of the parser is then:
\begin{minted}[escapeinside=\%\%]{scala}
val f = %\textcolor{gray}{flip(compose((\_ + \_).curried)(identity))}%
lazy val expr: Parsley[String] = chain.postfix(string("b"))(string("a").map(%\textcolor{gray}{f}%))
\end{minted}
%
The parser is now expressed in a much simplified form, in a similar style to the hand-written example in \cref{fig:leftrec-example-hand}!
The remaining challenge is to simplify the contents of the expression \scala{f}, which is tackled in \cref{sec:simplify-exprs}.

\subsection{Implementing Rewrites on the Parser \textsc{ast}}\label{sec:parser-rewrites}
Lawful simplifications are applied by a bottom-up transformation over the recursively defined \scala{Parser} \textsc{ast}.
Since there are many parser cases, this inevitably leads to repetitive and error-prone boilerplate code which simply exists to recursively propagate the transformation through each case.
To avoid this, the recursive traversal itself can be decoupled from the definition of the transformation function.
Although the traversal is still hand-written, this implementation is inspired by the generic traversal patterns offered by Haskell's \texttt{uniplate} library~\cite{mitchell_uniform_2007}.

\paragraph{Partial functions}
Scala supports \emph{partial functions}, which are functions only defined for a subset of its possible input values.
If invoked on an undefined input, this results in a runtime error.
A useful idiom utilising partial functions is the \scala{collect} method on collections, which combines functionality of \scala{filter} and \scala{map} in a clean manner.
This method will attempt to apply a partial function to each element in the collection, and only include the result if the function is defined.
In fact, \scala{collect} has already been used in earlier sections to inspect and gather \textsc{ast} nodes of interest in the Scalameta \textsc{ast}:
\begin{minted}{scala}
doc.tree.collect { case Term.Name(name) => name }
//                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
// A partial function only defined for Term.Name nodes, not on any other type of AST node
\end{minted}
%
Rewrite rules on parsers are most naturally expressed as a partial function, since they are only defined for certain parser cases.
Therefore, the traversal method \scala{transform} takes a partial function, applying it to nodes where it is defined.
The transformation is applied via a bottom-up traversal:
\begin{minted}{scala}
def transform(pf: PartialFunction[Parser, Parser]): Parser = {
  val p = this match {
    case p <*> q       => p.transform(pf) <*> q.transform(pf)
    case Zipped(f, ps) => ps.map(_.transform(pf)).zipped(f)
    case Pure(f)       => Pure(f)
    ...
  }
  // Apply the partial function if defined, otherwise return the original parser
  pf.applyOrElse(parser, identity[Parser])
}
\end{minted}
%
A \scala{rewrite} method can then be defined in terms of \scala{transform}, applying the partial function everywhere and re-applying it until it no longer makes a change.
This has the effect of applying a transformation exhaustively until a normal form is reached.
\begin{minted}{scala}
def rewrite(pf: PartialFunction[Parser, Parser]): Parser = {
  def pf0(p: Parser) = if (pf.isDefinedAt(p)) pf(p).rewrite(pf) else p
  this.transform(pf0)
}
\end{minted}
%
With this, any transformation on parsers can be defined without having to worry about recursion boilerplate: the act of traversal itself is fully abstracted away and encapsulated within the \scala{transform} method.
Using \scala{rewrite}, parser simplification can then be expressed in a clean and maintainable manner:
\begin{minted}{scala}
def simplify: Parser = this.rewrite {
  case FMap(FMap(p, f), g) => FMap(p, compose(g, f))
  case Pure(f) <*> Pure(x) => Pure(App(f, x))
  case u <|> Empty         => u
  case Pure(f) <|> _       => Pure(f)
  ...
}
\end{minted}
%
\paragraph{Extensibility and Safety}
Further design considerations are made to ensure the extensibility of this approach: the \scala{Parser} trait is sealed, which enables compiler warnings if a new \scala{Parser} case is added and the \scala{transform} method is not updated.
Although this formulation of the traversal is inspired by generic traversals, it still manually defines the traversal for each case: a safer approach would be to generically derive this.
In Scala, this would require the use of an external dependency such as \texttt{shapeless}\footnote{\url{https://github.com/milessabin/shapeless}},
which is overkill given the relative simplicity of the \scala{Parser} \textsc{adt}.

\subsection*{Discussion}
The design of the parser simplification process for \texttt{parsley-garnish} was not intended to closely follow the methods used in \texttt{parsley}, so it is remarkable that the two approaches have ended up being so similar.
However, in retrospect, this resemblance is not surprising given that the act of parser simplification and optimisation are fundamentally the same transformation.
Since both \texttt{parsley} and \texttt{parsley-garnish} represent the parser \textsc{ast} as a deep-embedded structure, it is natural that this transformation is implemented similarly in both cases as a bottom-up traversal over the abstract syntax.

This insight can be extended to any deep embedded \textsc{dsl} based on an algebra, where constructs within the \textsc{dsl} are subject to algebraic laws and operations.
It would be interesting to see an e\textsc{dsl} and linter pair that shares a unified data structure for its abstract syntax, in order to take full advantage of this duality.

\end{document}
