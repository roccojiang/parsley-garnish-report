\documentclass[../../main.tex]{subfiles}

\begin{document}

\ourchapter{Removing Left-Recursion}\label{sec:factor-leftrec}

\emph{Left-recursive} grammar rules are a common pattern to represent left-associativity.
Take for example the following definition of a left-associative addition operator:
\begin{equation*}
\nt{expr} ::= \nt{expr} \; \sym{+} \; \nt{term} \alt \nt{term}
\end{equation*}
%
Since the first production of $\nt{expr}$ is itself, this rule is said to be left-recursive.
This poses a problem for recursive-descent parsers, such as those that \texttt{parsley} produces:
it will try to parse $\nt{expr}$ by first trying to parse $\nt{expr}$, and so on, resulting in an unproductive infinite loop.

Although it is possible to address the issue by transforming the grammar with algorithms such as Paull's algorithm~\cite{moore_removing_2000},
in the context of parser combinators this is considered an anti-pattern by \textcite{willis_design-haskell_2021}.
They argue that this transformation obscures the original intent of the grammar, and exposes lower-level implementation details when this can be abstracted behind a combinator.
Instead, they propose that the idiomatic method to handle left-recursion in parser combinators is to use the \scala{chain} family of combinators~\cite{fokker_functional_1995}.
These combinators embody the behaviour of right-associating left-recursive rules and correcting the result back to a left-associative form.

Left-recursion often comes as a nasty surprise for novice users naÃ¯vely translating \textsc{bnf} grammars into parser implementations -- this issue is not unique to parser combinators, but also extends to many popular parser generators that use recursive-descent.
Thus, it would be beneficial to provide a linting rule for \texttt{parsley} that can warn users when parsers are left-recursive.
In fact, the next major release of \texttt{parsley} 5.0 will introduce a \scala{detectDivergence} combinator, which performs \emph{dynamic} analysis to detect unproductive looping at runtime.
Therefore, \texttt{parsley-garnish} could complement this functionality with an auto-fix rule to refactor left-recursive parsers to use \texttt{parsley}'s idiomatic \scala{chain} combinators.

\paragraph{Running example}
The following left-recursive parser and its transformation into a non-left-recursive form will be used as an example for this \namecref{sec:factor-leftrec}:
\begin{minted}{scala}
lazy val example: Parsley[String] = (example, string("a")).zipped(_ + _) | string("b")
\end{minted}
%
The \scala{example} parser intends to express the following simple grammar expressed using left-recursion. The goal is to refactor \scala{example} so that it retains the intended semantics, but is transformed into a parser that \texttt{parsley} can handle correctly.
\begin{equation*}
\nt{example} ::= \nt{example} \; \sym{a} \alt \sym{b}
\end{equation*}

\section{The Left-Recursion Factoring Transformation}
\texttt{parsley-garnish} bases its left-recursion factoring transformation on the work of \textcite{baars_leftrec_2004}, adapted to fit the \textsc{peg} semantics of \texttt{parsley}.
At a high-level, the transformation involves ``unfolding'' each non-terminal production into three parts:
\begin{itemize}
  \item \scala{results}: The semantic actions of the parser, if it can derive the empty string. Conceptually, this has type \scala{Option[A]} where \scala{A} is the type of the result.
  \item \scala{nonLeftRec}: The non-left-recursive part of the parser that does not derive the empty string. This will have some type \scala{Parsley[A]}.
  \item \scala{leftRec}: The left-recursive call, which in the general left-recursive case, corresponds to a repeated postfix operator of type \scala{Parsley[A => A]}. This is a function which requires the semantics of the left-recursive non-terminal argument.
\end{itemize}
%
This transformation is applied in-order to each parser in the source file, replacing the original parser with its factored form if it was left-recursive.
An unfolded parser is recombined using \scala{chain.postfix}: this combinator encapsulates the general form of left-associative parsing, and most other iterative combinators can be derived from it~\cite{willis_parsley_2024}.
\begin{minted}{scala}
def transform(
  results: Option[A],
  nonLeftRec: Parsley[A],
  leftRec: Parsley[A => A]
): Parsley[A] = {
  val result: Parsley[A] = results match {
    case None    => empty
    case Some(x) => pure(x)
  }
  // The type signature of postfix in Parsley:
  // def postfix[A](p: Parsley[A])(op: => Parsley[A => A]): Parsley[A]
  chain.postfix(nonLeftRec | results)(leftRec)
}
\end{minted}

\section{Necessary Infrastructure}\label{sec:leftrec-infra}
The comparatively simple linting rules discussed in the previous \namecref{sec:simple-rules} were implemented by directly inspecting the generic Scala \textsc{ast} provided by Scalafix.
However, even though \texttt{parsley} programs are written in Scala, it is important to remember that \texttt{parsley} is a \textsc{dsl} borrowing Scala as a host language.
Domain-specific transformations like left-recursion factoring are therefore naturally defined as transformations on the \texttt{parsley} \textsc{ast}, at a higher level of abstraction than the generic Scala \textsc{ast}.
Thus, this \namecref{sec:leftrec-infra} discusses the extra infrastructure used to support the left-recursion factoring transformation:
\begin{itemize}
  \item Firstly, \cref{sec:parser-ast-motivation} motivates the idea of using an intermediate \textsc{ast} representation for parsers, distinct from the general-purpose Scala \textsc{ast}.
  \item Following this, \cref{sec:lifting-parsers} shows how the source Scala \textsc{ast} is converted into this intermediate representation.
  \item Finally, \cref{sec:lowering-parsers} discusses how the intermediate \textsc{ast} is converted back into Scala code so that it can be applied as a Scalafix patch.
\end{itemize}

\subsection{An Intermediate \textsc{ast}}\label{sec:parser-ast-motivation}
The transformations described by \textcite{baars_leftrec_2004} require an explicit representation of the grammar and production rules so that they can be inspected and manipulated before generating code.
They achieve this by representing parsers as a deep-embedded datatype in the form of an intermediate \textsc{ast}, similarly to \texttt{parsley}.

Since \texttt{parsley-garnish} is a linter, by nature, it has access to an explicit grammar representation in the form of the full \scala{scala.meta.Tree} \textsc{ast} of the source program.
However, this datatype represents general-purpose abstract Scala syntax, rather than the abstract syntax of a specialised parser combinator \textsc{dsl}.
This makes it not well-suited for performing domain-specific operations over the \textsc{ast}.

Take for example the task of combining two \textsc{ast} nodes \scala{Term.Name("p")} and \scala{Term.Name("q")}, representing named parsers \scala{p} and \scala{q}, with the combinator \scala{<*>} (pronounced ``ap'').
This operation can be concisely expressed with Scalameta quasiquotes, rather than manually writing out the full explicit \textsc{ast}:
\begin{minted}{scala}
q"p <*> q" ==
  Term.ApplyInfix(
    Term.Name("p"),
    Term.Name("<*>"),
    Type.ArgClause(Nil),
    Term.ArgClause(List(Term.Name("q")), None)
  )
\end{minted}
However, the  operation of inspecting the individual parsers \scala{p} and \scala{q} is not as straightforward.
Although quasiquotes can be used as extractor patterns in pattern matching, this usage is discouraged due to limitations in their design that makes it easy to accidentally introduce match errors\footnote{\url{https://scalameta.org/docs/trees/guide.html#with-quasiquotes-1}}.
Thus, extracting the parsers necessitates a long-winded pattern match like so:
\begin{minted}{scala}
val ap = SymbolMatcher.normalized("parsley.Parsley.`<*>`")
def deconstructAp(parser: Term) = parser match {
  case Term.ApplyInfix(p, ap(_), _, Term.ArgClause(List(q), _)) => (p, q)
}
\end{minted}
This involves dealing with abstract general-purpose syntax constructs like \scala{Term.ApplyInfix}, which are low-level details irrelevant to the task of manipulating parsers.
Although this is not an issue for simple one-off transformations, for more specialised transformations like left-recursion factoring, it would be desirable to abstract away from these low-level syntactic details.
This motivates the need for an higher-level, intermediate \textsc{ast} representation that is more specialised to the domain of parser combinators.

\subsubsection{The Parser \textsc{adt}}
\texttt{parsley-garnish} therefore takes a similar approach as \textcite{baars_leftrec_2004} and \texttt{parsley} itself, building an intermediate \textsc{ast} as a deep-embedded parser combinator tree.
\Cref{fig:parser-adt} shows how this is implemented as a \scala{Parser} algebraic data type (\textsc{adt}).
All \scala{Parser} types represent \texttt{parsley} combinators, with the sole exception of \scala{NonTerminal} to represent references to named parsers.

\begin{figure}[htbp]
\begin{minted}{scala}
trait Parser
case class NonTerminal(ref: Symbol) extends Parser
case class Pure(x: Term) extends Parser
case object Empty extends Parser
case class <*>(p: Parser, q: Parser) extends Parser
case class <|>(p: Parser, q: Parser) extends Parser
case class Str(s: String) extends Parser
case class Chr(c: Char) extends Parser
\end{minted}
\caption{A subset of the \scala{Parser} \textsc{adt}, representing the core combinators in \texttt{parsley-garnish}.}
\label{fig:parser-adt}
\end{figure}

\paragraph{Deconstructing parsers}
Scala allows users to define symbolic class names (as evidenced by the definitions of \scala{<*>} and \scala{<|>} in \cref{fig:parser-adt}), and provides syntactic sugar to pattern match on these constructors using infix notation.
This results in a very natural and readable pattern matching syntax:
\begin{minted}{scala}
def deconstructAp(parser: Parser) = parser match { case p <*> q => (p, q) }
\end{minted}

\paragraph{Constructing parsers}
Defining infix operators as extension methods on the \scala{Parser} trait provides a similar syntactic sugar for constructing parsers:
\begin{minted}{scala}
extension (p: Parser) {
  def <*>(q: Parser) = <*>(p, q)
  def |(q: Parser) = <|>(p, q)
  def map(f: Term) = FMap(p, f)
}
extension (ps: List[Parser]) {
  def zipped(f: Term) = Zipped(f, ps)
}
\end{minted}
%
This makes the syntax for writing \scala{Parser} terms feel natural and similar to writing \texttt{parsley} code.
For example, notice how constructing the \emph{code} representation of the \scala{example} parser resembles how the original parser itself would be written:
\begin{minted}{scala}
val EXAMPLE = NonTerminal(Sym(Term.Name("example").symbol))  

// val example: Parsley[String] =     (example,  string("a")).zipped(  _ + _ ) | string("b")
   val example: Parser          = List(EXAMPLE,     Str("a")).zipped(q"_ + _") |    Str("b")
\end{minted}

\subsection{Lifting to the Intermediate Parser \textsc{ast}}\label{sec:lifting-parsers}
Converting the raw Scala \textsc{ast} to this intermediate parser combinator \textsc{ast} requires the following basic operations:
\begin{enumerate}
  \item Identifying all named parsers defined in the source program -- these correspond to non-terminal symbols in the grammar.
  \item Lifting the definition each parser into the intermediate \textsc{ast}, i.e. a \scala{Parser} object.
  \item Collecting these into a map to represent the high-level grammar -- the unique symbol of each named parser is mapped to its corresponding \scala{Parser} object, along with extra metadata required for the transformation.
\end{enumerate}
%
Most importantly, this metadata includes a reference to a parser's original node in the Scala \textsc{ast}, so lint diagnostics or code rewrites can be applied to the correct location in the source file:
\begin{minted}{scala}
case class ParserDefn(name: Term.Name, parser: Parser, tpe: Type.Name, originalTree: Term)
\end{minted}

\subsubsection{Identifying Named Parsers}
Finding \textsc{ast} nodes corresponding to the definition sites of named parsers involves pattern matching on \scala{val}, \scala{var}, and \scala{def} nodes with a type inferred as some \scala{Parsley[_]}.
This type information is queried using the Scalafix semantic \textsc{api} on the node's symbol information.
Consider the labelled \textsc{ast} structure of the \scala{example} parser:
\begin{minted}{scala}
// lazy val example: Parsley[String] = (example, string("a")).zipped(_ + _) | string("b")
// ^^^^     ^^^^^^^  ^^^^^^^^^^^^^^^   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
// mods      pats        decltpe                             rhs

val exampleTree = Defn.Val(
  mods = List(Mod.Lazy()),
  pats = List(Pat.Var(Term.Name("example"))),
  decltpe = Some(
    Type.Apply(Type.Name("Parsley"), Type.ArgClause(List(Type.Name("String"))))
  ),
  rhs = Term.ApplyInfix(...)
)
\end{minted}
%
% In this case, the type of \scala{example} is explicitly annotated by the user since this is required for recursive definitions.
% However in general, users will not explicitly annotate the types of their parsers, allowing the Scala compiler to infer the type.
Note that the \scala{decltpe} field refers to the \emph{syntax} of the explicit type annotation, not the \emph{semantic} information the variable's inferred type.
Therefore, this field will not always be present, so in the general case, the type must be queried via a symbol information lookup:
\begin{minted}{scala}
exampleTree match {
  case Defn.Val(_, List(Pat.Var(varName)), _, body) =>
    println(s"qualified symbol = ${varName.symbol}")
    // Query the symbol information of the variable name, and get its type signature
    varName.symbol.info.get.signature match {
      // Scalameta treats this as a zero-arg method, so the relevant part is its return type
      case MethodSignature(_, _, returnType) =>
        println(s"type = $returnType")
        println(s"structure of type object = ${returnType.structure}")
    }
}
// qualified symbol = path/to/package/ObjectName.example.
// type = Parsley[String]
// structure of type object = TypeRef(
//   NoType,
//   Symbol("parsley/Parsley#"),
//   List(TypeRef(NoType, Symbol("scala/Predef.String#"), List()))
// )
\end{minted}
Seeing that the type of this \textsc{ast} node is \scala{Parsley[String]}, \texttt{parsley-garnish} can then proceed to convert the \scala{rhs} term into a \scala{Parser} \textsc{adt} object.
The map entry uses the fully qualified symbol for \scala{example} as the key, and the lifted \scala{Parser} object as the value.

\subsubsection{Converting Scalameta Terms to the Parser \textsc{adt}}
Having identified the \textsc{ast} nodes which represent parsers, they need to be transformed into the appropriate \scala{Parser} representation.
This involves pattern matching on the \scala{scala.meta.Term} to determine which parser combinator it represents, and then constructing the appropriate \scala{Parser} instance.

Each \scala{Parser} defines a partial function \scala{fromTerm} to instantiate a parser from the appropriate \scala{scala.meta.Term}.
These \scala{fromTerm} methods perform the menial work of pattern matching on the low-level syntactic constructs of the Scala \textsc{ast}.
All \scala{fromTerm} methods are combined to define the \scala{toParser} extension method on \scala{scala.meta.Term} -- this is where \textsc{ast} nodes are lifted to their corresponding \scala{Parser} representation.

The pattern matching example from \cref{sec:parser-ast-motivation} makes a reappearance in the definition of \scala{<*>.fromTerm}, where the arguments to the \scala{<*>} combinator are instead recursively lifted to \scala{Parser} objects:
% Use Scalafix's \scala{SymbolMatcher} to match tree nodes that resolve to a specific set of symbols.
% This makes use of semantic information from SemanticDB, so we are sure that a \scala{<*>} is actually within the \scala{parsley.Parsley} package, rather than some other function with the same name.
% This is much more robust compared to HLint, which suffers from false positives due to its reliance on syntactic information only.
\begin{minted}{scala}
// Type signatures in Parsley:
// p: Parsley[A => B], q: =>Parsley[A], p <*> q: Parsley[B]
case class <*>(p: Parser, q: Parser) extends Parser
object <*> {
  // Match the specific symbol for parsley's <*> combinator
  val matcher = SymbolMatcher.normalized("parsley.Parsley.`<*>`")

  def fromTerm: PartialFunction[Term, <*>] = {
    // Pattern match succeeds only if the term has the structure 'p <*> q'
    case Term.ApplyInfix(p, matcher(_), _, Term.ArgClause(List(q), _)) =>
      p.toParser <*> q.toParser
  }
}
\end{minted}
%
Where a combinator takes a non-parser argument, this is treated as a black box and kept as a raw \textsc{ast} node of type \scala{scala.meta.Term}:
\begin{minted}{scala}
// x: A, pure(x): Parsley[A]
case class Pure(x: Term) extends Parser
object Pure {
  val matcher = SymbolMatcher.normalized("parsley.ParsleyImpl.pure")

  def fromTerm: PartialFunction[Term, Pure] = {
    // expr is an opaque AST node that cannot be further inspected
    case Term.Apply(matcher(_), Term.ArgClause(List(expr), _)) => Pure(expr)
  }
}
\end{minted}

\subsubsection{Building the Grammar Map}
The overall process of converting the source file \textsc{ast} to a high-level map of the grammar can therefore be expressed as a single traversal over the \textsc{ast}:
\begin{minted}{scala}
// Encapsulate all valid pattern matches into a single extractor object
object VariableDecl {
  def unapply(tree: Tree): ParserDefn = tree match {
    // isParsleyType uses symbol info to check if variable type is Parsley[_]
    case Defn.Val(_, List(Pat.Var(varName)), _, body) if isParsleyType(varName) =>
      // If the pattern match is successful, convert the definition body to a Parser
      // Collect metadata and bundle into a parser definition object
      ParserDefn(
        name = varName,
        parser = body.toParser,
        tpe = getParsleyType(varName),
        originalTree = body
      )
    // ... similar cases for Defn.Var and Defn.Def
  }
}

type Grammar = Map[Symbol, ParserDefn]
val grammar: Grammar = doc.tree.collect {
  // Every AST node that satisfies the pattern match is added to the map
  case VariableDecl(parserDef) => parserDefn.name.symbol -> parserDef
}.toMap
\end{minted}

\subsection{Lowering Back to the Scalameta \textsc{ast}}\label{sec:lowering-parsers}
After all necessary transformations have been applied to parser terms, the final step is to convert them back to a textual representation to be applied as a Scalafix patch.
Parsers can be lowered back to \scala{scala.meta.Term} nodes by the inverse of the original \scala{fromTerm} transformation.
The \scala{Parser} trait defines this transformation as the method \scala{term}, using quasiquotes to simplify the construction of the \scala{scala.meta.Term} nodes.
For example:
\begin{minted}{scala}
case class Zipped(func: Function, parsers: List[Parser]) extends Parser {
  val term: Term = q"(..${parsers.map(_.term)}).zipped(${func.term})"
}
\end{minted}
%
The \scala{Parser} trait can then define a \scala{toString} method based on Scalameta's \textsc{ast} pretty-printer on the \scala{term} field.
This ``stringified'' term is therefore guaranteed to be syntactically well-formed and is the appropriate type expected by Scalafix's \scala{Patch} methods.

\section{Implementing the Left-Recursion Transformation}
With the \scala{Parser} \textsc{ast} defined, it is now possible to implement the left-recursion factoring transformation in a more high-level manner.
Using the \scala{grammar} map collected previously, the overall transformation can be summarised as follows (in Scala-like pseudocode for brevity):
\begin{minted}{scala}
val transformedGrammar = grammar.to(mutable.Map)
for (currentNT <- grammar.keys) {
  // Unfold each non-terminal parser into its three parts
  val (results, nonLeftRec, leftRec) = unfold(transformedGrammar, currentNT)
  // Update the grammar with the recombined postfix parser if it was left-recursive
  transformedGrammar(currentNT).parser = transform(results, nonLeftRec, leftRec)
}
// Generate rewrite patches for each parser definition
transformedGrammar.mapValues { defn =>
  Patch.replaceTree(defn.originalTree, defn.parser.toString)
}
\end{minted}
%
The unfolding transformation is defined as follows, which is dynamically dispatched to the appropriate combinator's \scala{unfold} method:
\begin{minted}{scala}
def unfold(env: Grammar, currentNT: Symbol) =
  env(currentNT).parser.unfold(currentNT, env, visited = Set.empty)
\end{minted}

\subsection{Unfolding the Core Combinators}
The most important core combinators in the left-recursion transformation are \scala{NonTerminal}, \scala{Pure}, \scala{Empty}, \scala{<|>}, and \scala{<*>}.
Character combinators such as \scala{Str} (\scala{string}), \scala{Chr} (\scala{char}), and \scala{Item} (\scala{item}), although technically handled by \texttt{parsley-garnish} as primitives, are grouped together as they behave in a simple and uniform manner.
The rest of the combinators in \texttt{parsley} are defined in terms of the primitive combinators, and are desugared into the core combinators during unfolding.

\paragraph{Non-terminals}
Non-terminals are the primary base case of the recursive unfolding transformation.
There are three cases to consider when a non-terminal symbol is encountered:
\begin{itemize}
  \item This non-terminal is the same as the current non-terminal being analysed, which means it may be in a left-recursive position. Recall that the \scala{leftRec} result corresponds to a function, where the call to the left-recursive non-terminal is stripped off. Therefore in this case, the left-recursive call is the \scala{identity} function which just returns its argument, i.e. the non-terminal itself. It is not an issue if the non-terminal is not in left-recursive position, as the \scala{leftRec} result will be subsumed by the \scala{nonLeftRec} result during the final recombination.
  \item The non-terminal refers to a different non-terminal, but has already been visited in the current unfolding process. This means it should not be recursively visited again, as it has already been factored out. It is not left-recursive and the \scala{nonLeftRec} part is just a reference to this non-terminal's name.
  \item The non-terminal refers to a different non-terminal that has not been visited yet. In this case, the non-terminal is recursively unfolded, and the \scala{visited} set is updated to include this non-terminal.
\end{itemize}
%
The three cases can be implemented as so:
\begin{minted}{scala}
case class NonTerminal(ref: Symbol) extends Parser {
  def unfold(currentNT: Symbol, env: Grammar) =
    if (ref == currentNT) (None, Empty, Pure(q"identity"))
    else if (visited.contains(ref)) (None, NonTerminal(ref), Empty)
    else env(ref).parser.unfold(currentNT, env, visited + ref)
}
\end{minted}

\paragraph{Base cases}
The base cases are mostly straightforward.
The unfolded \scala{results} portion can be reasoned with by the combinators' correspondence to \textsc{peg} expressions~\cite{eichenroth_fast_2022}, as shown in \cref{tab:base-case-empties}. If the combinator can succeed by parsing the empty string, \scala{results} is a \scala{Some} value of its semantic action, otherwise it is \scala{None}.
The other two portions are also easy: none are left-recursive, and if the combinator consumes input on success then \scala{nonLeftRec} is just the combinator itself.
Thus, the base cases can be summed up as follows:
\begin{minted}{scala}
/* Pure */                 (Some(x), Empty, Empty)
/* Empty */                (None, Empty, Empty)
/* p: Str | Chr | Item */  (None, p, Empty)
\end{minted}

\begin{table}[htbp]
\centering
\begin{tabular}{@{}lp{0.75\textwidth}@{}}
\toprule
Combinator        & Can succeed without consuming input?                                                                                                               \\ \midrule
\scala{pure(x)}   & Yes, semantic action is \scala{x}.                                                                                                                         \\
\scala{empty}     & No, combinator fails immediately regardless of input.                                                                                              \\
\scala{string(s)} & Functionally, no. Can theoretically be given the empty string \scala{""}, but this is illegal in \texttt{parsley} and triggers a runtime exception. \\
\scala{char(c)}   & No, always consumes the given character.                                                                                                           \\
\scala{item}      & No, always consumes any single character.                                                                                                          \\ \bottomrule
\end{tabular}%
\caption{Semantic action (\scala{results}) portion behaviour for each base case.}
\label{tab:base-case-empties}
\end{table}

\paragraph{Choice (\scala{<|>})}
This recursive case is also relatively simple: each branch is unfolded, then the \scala{nonLeftRec} and \scala{leftRec} portions are recombined with the \scala{|} combinator.
The \scala{results} portion is that of the left branch if it can derive the empty string, otherwise it is the right branch.
This behaviour differs slightly from the original presentation of the transformation by \textcite{baars_leftrec_2004}, where \scala{|} is based on \textsc{cfg} semantics.
The consequence of this is that choice is unbiased in the original transformation, triggering an ambiguity error if both branches can succeed without consuming input.
However, since \texttt{parsley} uses \textsc{peg} semantics, this ambiguity is not possible --
the choice operation represented by the \scala{|} combinator is \emph{left-biased}, so if the left parser succeeds the right parser is not attempted.

\begin{minted}{scala}
case class <|>(p: Parser, q: Parser) extends Parser {
  def unfold() = {
    val ((pe, pn, pl), (qe, qn, ql)) = (p.unfold, q.unfold)
    (pe.orElse(qe), pn | qn, pl | ql)
  }
}
\end{minted}

\paragraph{Ap (\scala{<*>})}
This is an important case, as \texttt{parsley-garnish} chooses to use \scala{<*>} as the primitive combinator for composing parsers.
It is also the most complex:
\begin{itemize}
  \item \scala{p <*> q} can succeed without consuming input only if \emph{both} \scala{p} and \scala{q} can do so. Parser combinators abide by the law that \scala{pure(f) <*> pure(x) = pure(f(x))}, so the resulting semantic action is that of \scala{p} applied as a function to the semantic action of \scala{q}.
  \item In the \scala{nonLeftRec} and \scala{leftRec} portions, if \scala{p} can succeed without consuming input, then \scala{q} must be subjected to the semantic value corresponding to \scala{p}~\cite{swierstra_deterministic_1996}. This is achieved using the result shown in \cref{eq:ap-leftrec}, which is a special case of grammar right-factoring in reverse.
  \begin{itemize}
    \item The \scala{leftRec} portion requires re-associating semantic actions back to the left, which necessitates using the \scala{flip} higher-order function. Therefore, the left branch of the \textsc{rhs} in \cref{eq:ap-leftrec} is reformulated as \scala{p.map(flip) <*> q}.
    \item Since \scala{leftRec} is a parser of a function, the right branch also needs adjusting: the function composition operation must be used in order to apply the function to \scala{q} with the \scala{<*>} combinator.
  \end{itemize}
\end{itemize}

\begin{equation} \label{eq:ap-leftrec}
\text{\haskell{(p <|> pure f) <*> q}} \quad \Rightarrow \quad \text{\haskell{(p <*> q) <|> (f <$> q)}}
\vspace{3ex} % shh...
\end{equation}
%
Given the above observations, the implementation of the \scala{<*>} combinator's unfolding is as follows:
\begin{minted}{scala}
case class <*>(p: Parser, q: Parser) extends Parser {
  def unfold() = {
    val ((pe, pn, pl), (qe, qn, ql)) = (p.unfold, q.unfold)

    val result = for {
      f <- pe
      x <- qe
    } yield App(f, x)

    val nonLefts = {
      val lnl = pn <*> q
      val rnl = pe.map(q"f => qn.map(f)").getOrElse(Empty) // f <$> qn
      lnl | rnl
    }

    val lefts = {
      val llr = pl.map(q"flip") <*> q
      val rlr = pe.map(q"$ql.map(compose)").getOrElse(Empty) // f.map(compose) <$> ql
      llr | rlr
    }

    (result, nonLefts, lefts)
  }
}
\end{minted}

\subsection{Composite Combinators}\label{sec:desguar-combinators}
The remaining combinators are defined in terms of the core combinators, and are unfolded by recursively unfolding their constituent parts.
For example, the \scala{map} combinator is defined as \scala{p.map(f) = pure(f) <*> p}, so its unfolding is simply implemented as:
\begin{minted}{scala}
case class FMap(p: Parser, f: Term) extends Parser {
  def unfold() = (Pure(f) <*> p).unfold
}
\end{minted}
%
Further high-level combinators are defined in a similar manner.
The improved sequencing combinators \scala{lift} and \scala{zipped}, as well as bridge constructors using the \emph{Parser Bridges} design pattern~\cite{willis_design_2022}, represent a further generalisation of the \scala{map} combinator:
\begin{minted}{scala}
liftN(f, p1, ..., pN) // explicit lift syntax, where f is a function of arity N
f.lift(p1, ..., pN) // implicit lift syntax
(p1, ..., pN).zipped(f) // zipped syntax, improves Scala's ability to infer types
F(p1, ..., pN) // parser bridge pattern, abstracts the construction of f behind bridge F

// All are equivalent to the following desugared form,
// which is idiomatic in Haskell, but not in Scala for performance reasons
= pure(f.curried) <*> p1 <*> ... <*> pN
\end{minted}
%
These are handled in \texttt{parsley-garnish} as the \scala{LiftLike} family of combinators, which converts them into the desugared form in terms of core combinators \scala{pure} and \scala{<*>}, allowing the unfolding transformation to be applied:
\begin{minted}{scala}
trait LiftLike extends Parser {
  // foldLeft builds a parser of the form 'pure(f.curried) <*> p1 <*> ... <*> pN'
  def unfold() = parsers.foldLeft(Pure(q"$func.curried"))(_ <*> _).unfold
}
\end{minted}

\subsection{Defining Utility Functions}\label{sec:leftrec-utils}
In various places within the unfolding transformations, three higher-order functions are utilised, which may not be provided by the Scala standard library:
\begin{itemize}
  \item The flip function reverses the order of arguments applied to a function. This is not defined in the standard library, so it must be defined manually.
  \item Function composition is defined in the standard library, but a more versatile curried version is required by the transformation, so it is also defined manually.
  \item The identity function \scala{identity[A]: A => A} is defined in the standard library.
\end{itemize}
%
Therefore, \texttt{parsley-garnish} will insert the following definitions into the source file as a patch:
\begin{minted}{scala}
def flip[A, B, C](f: A => B => C)(x: B)(y: A): C = f(y)(x)
def compose[A, B, C](f: B => C)(g: A => B)(x: A): C = f(g(x))
\end{minted}
%
Although this is not very aesthetically pleasing, it is necessary to bring these higher-order functions into scope for the transformed code to make use of them.

\subsection*{Success...?}
With the unfolding transformations defined for all core combinators, the left-recursion factoring transformation is now complete.
Running the transformation on the \scala{example} parser yields the output in \cref{fig:leftrec-example-bad}.
%
\begin{figure}[htbp]
\begin{minted}{scala}
def flip[A, B, C](f: A => B => C)(x: B)(y: A): C = f(y)(x)
def compose[A, B, C](f: B => C)(g: A => B)(x: A): C = f(g(x))

lazy val example: Parsley[String] = chain.postfix(
  empty | (empty.map((_ + _).curried) | empty <*> example) <*> string("a")
    | string("b") | empty
)(
  (empty.map(flip) <*> example | pure(identity).map(compose((_ + _).curried)))
    .map(flip) <*> string("a")
    | empty | empty
)
\end{minted}
\caption{The initial attempt at factoring out left-recursion from the \scala{example} parser.}
\label{fig:leftrec-example-bad}
\end{figure}

\noindent % TODO: keep/remove this depending on if needed, based on positioning of the figure
This is... disappointing, to say the least.
There are \emph{many} things wrong with the transformed output:
\begin{itemize}
  \item The parser is horrendously complex and unreadable, its intent entirely obfuscated in a sea of combinators. It's especially frustrating that there are so many \scala{empty} combinators, when both \scala{p | empty} and \scala{empty | p} are just equivalent to \scala{p}.
  \item Having to define the \scala{flip} and \scala{compose} functions is not ideal, but inlining them as lambdas would make the code even worse.
  \item Even worse, the parser does not even typecheck -- unlike classical Hindley-Milner-based type systems, Scala only has \emph{local} type inference~\cite{cremet_core_2006}. As a result, the compiler is unable to correctly infer correct types for \scala{flip} and also asks for explicit type annotations in the lambda \scala{(_ + _).curried}.
\end{itemize}
% foreshadowing lol
The result is discouraging especially because it is not impossible to factor out the left-recursion in a nice manner:
a hand-written equivalent using \scala{postfix} would resemble the concisely defined parser in \cref{fig:leftrec-example-hand}.
There is still hope, though -- if the \scala{empty} combinators can be removed and something is done about the higher-order functions, perhaps \cref{fig:leftrec-example-bad} could be salvaged into something that looks more like the human-written version.

\begin{figure}[htbp]
\begin{minted}{scala}
lazy val example: Parsley[String] = chain.postfix(string("b"))(string("a").as(_ + "a"))
\end{minted}
\caption{An idiomatic way to express the \scala{example} parser using \scala{chain.postfix}.}
\label{fig:leftrec-example-hand}
\end{figure}

\end{document}
