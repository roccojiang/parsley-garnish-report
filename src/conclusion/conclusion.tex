\documentclass[../../main.tex]{subfiles}

\begin{document}

\ourchapter{Related Work}
The work in this project draws inspiration from a variety of areas, which are briefly summarised in this chapter.

\section{Library-Specific Linters}
% Linters and related static analysers require a non-trivial amount of work to implement, so they are generally developed for general-purpose languages.
% Library- and \textsc{dsl}-specific linters are relatively uncommon as they often do not have enough users to justify the effort to develop the tooling.
% Much of existing literature on the topic therefore focuses on lowering the development cost to develop \textsc{dsl}-specific tooling.
\textcite{renggli_domain-specific_2010} acknowledge that generic language-level linters and static analysers fail to capture best practices and common errors particular to specialised domains.
This is a sentiment shared by \textcite{gregor_stllint_2006}, who discuss how statically checking library semantics is very different from checking language semantics, arguing that this necessitates new program representation at the appropriate level of abstraction.
The work in this project corroborates these claims, as the work in \cref{sec:impl} demonstrates that the generic Scala \textsc{ast} is not at a sufficient level of abstraction to perform complex parser transformations.
\textcite{gregor_stllint_2006} also use a similar terminology to \texttt{parsley-garnish} of ``lifting'' their static checker from language to library level.

The situation that \textcite{renggli_domain-specific_2010} faced is similar to the one in this project, as they worked with an embedded \textsc{dsl}, but in Smalltalk.
For their static analyser, the authors also had access to a Scalafix-like tool which reuses the existing \scala{ast} of the host language.
However, they opted to define their own separate \textsc{dsl} to specify lint and rewrite rules.
In contrast, this project argues that the most ergonomic approach is to model the linter \textsc{ast} on the original \textsc{ast} of the \textsc{dsl} itself -- this allows \texttt{parsley-garnish} to manipulate \textsc{ast}s of parsers in a high-level declarative manner comparable to writing standard \texttt{parsley} code.

\section{Left-Recursion Removal}
The need to remove left-recursion from parsers is not a new problem, as many popular parser-writing tools such as \textsc{antlr}~\cite{parr_antlr_2013} produce recursive-descent parsers.
Classical left-factoring algorithms such as Paull's algorithm~\cite{moore_removing_2000} and the left-corner transform~\cite{rosenkrantz_deterministic_1970} have been around for decades.
The idea of using the \scala{chain} family to idiomatically write left-associative parsers using parser combinators is also rather established~\cite{fokker_functional_1995}, and the left-recursion transformation algorithm in \texttt{parsley-garnish} is itself based on work from 2004~\cite{baars_leftrec_2004}.
However, the context in which this transformation is applied is relatively novel, as it is implemented as a code rewrite rule for a linter.
Since the output of the transformation is user-facing, rather than generated code, it must be readable and understandable to the end user -- this was one of the key challenges faced in this project.

\section{Metaprogramming and Domain-Specific Languages}
The work in \cref{sec:impl} draws many parallels to techniques in the field of metaprogramming, especially in its intersection with \textsc{dsl}s.
Squid~\cite{parreaux_squid_2017,parreaux_quoted_2017,parreaux_unifying_2017} implements quasiquotes for Scala 2.11 and 2.12 that, unlike Scalameta's quasiquotes, are type-safe and hygienic.
These quasiquotes also have rudimentary function inlining features, similar to the $\beta$-reduction and normalisation techniques used in this project.
Squid quasiquotes were used to perform multi-staged rewrite-based optimisations on a linear-algebra \textsc{dsl}~\cite{shaikhna_finally_2019}, generating optimised code using the same flavour of approach as \texttt{parsley} Haskell~\cite{willis_staged_2023,willis_parsley_2024}.
This \textsc{dsl}, similar to parser combinators, is highly based on algebraic laws, so there are many similarities in the optimisation techniques used in both projects.
By the observation in \cref{sec:simplify-parsers}, therefore, this work is dual to the simplification work achieved in \texttt{parsley-garnish} -- it is possible to adapt the work used by the authors to develop a linter for their \textsc{dsl}.

Scala 3's macro system~\cite{stucki_multi-stage_2021} has similar type-safety and hygiene guarantees as Squid, and supports $\beta$-reduction on staged \scala{Expr} trees.
These techniques supersede the work in \cref{sec:simplify-exprs}, which was necessitated only because Scalameta trees do not have the same functionalities.
Squid and Scala 3 macros are superior to the expression representation in this project in the sense that they formalise their type-safety and hygienic properties.

Finally, as already noted in \cref{sec:simplify-exprs}, the implementation of the \scala{Expr} \textsc{ast} also shares similarities with the \haskell{Defunc} and \haskell{Lam} infrastructures for code optimisation in \texttt{parsley} Haskell.

\ourchapter{Conclusion}
This project has presented a number of lint rules for the \texttt{parsley} parser combinator library:
\begin{itemize}
  \item \emph{Ambiguous Implicit Conversions} (\cref{sec:ambiguous-implicits}) alerts the user when multiple conflicting implicit conversions are in scope for their parsers, providing further context why the Scala compiler rejects their program.
  \item \emph{No Explicit Implicit Conversions} (\cref{sec:no-explicit-implicits}) automatically removes unnecessary explicit calls to the implicit conversion methods in \texttt{parsley}, which is a code smell.
  \item \emph{Factor Left-Recursion} (\cref{sec:factor-leftrec} and \cref{sec:leftrec-revisited}) rewrites unproductive left-recursive parsers into an idiomatic form that \texttt{parsley} supports. In cases where this cannot be automatically fixed, the rule warns the user that their parser will cause an infinite loop at runtime.
  \item \emph{Simplify Parsers} (\cref{sec:simplify-parsers-rule}) suggests and applies simplifications to parsers based on the rules of parser laws.
  \item \emph{Avoid Parser Redefinitions} (\cref{sec:avoid-redefinitions-rule}) suggests and applies rewrites to parsers that accidentally redefine existing higher-level combinators in the \texttt{parsley} \textsc{api}.
\end{itemize}
%
%  For static checkers to be useful to the programmer, they must operate at or near the same level of abstraction as the source code itself.
Implementing these rules necessitated the development of intermediate \textsc{ast} representations to improve the static inspectability of parser and expression terms.
The \scala{Parser} \textsc{ast} (\cref{sec:parser-ast-motivation} and \cref{sec:simplify-parsers}) models the \texttt{parsley} \textsc{dsl}, allowing \emph{code} of parsers to be manipulated in a high-level manner, as if they were parsers themselves.
It provides a high-level interface for writing syntax-directed transformations on parser terms, and most importantly handles the burden of simplifying parser terms into a readable form, based on similar optimisation techniques used in \texttt{parsley} itself.
% declarative manner of writing rewrite rules
The \scala{Expr} \textsc{ast} (\cref{sec:simplify-exprs} models an extension of the $\lambda$-calculus, allowing static representation of expressions to be partially evaluated and normalised to a simpler form.

\Cref{sec:eval-leftrec} shows that the left-recursion rule is effective at refactoring parsers for the majority of cases, representing a success for both the transformation algorithm itself, but also the internal \scala{Parser} and \scala{Expr} infrastructure that simplifies terms to a readable form.

\section{Future Work}
% Separate into practical (improvements to parsley-garnish) and theoretical (cool research things)?
Other than the obvious of adding more lint rules to \texttt{parsley-garnish}, and those already discussed in the body of the report, there are several avenues for future work that could be pursued.

\subsection{Implementing Left-Recursion Factoring in \texttt{parsley}}
Implementing the left-recursion factoring transformation in \texttt{parsley} itself would allow users to directly write parsers in left-recursive form without needing to transform it into a \scala{chain} combinator, whether by hand or via \texttt{parsley-garnish}.
This is possible to achieve in \texttt{parsley}: \cref{sec:simplify-parsers} discusses the relationship between the \texttt{parsley-garnish} \scala{Parser} \textsc{ast} and \texttt{parsley}'s own internal \textsc{ast}.
Since \texttt{parsley} is introspective enough to be able to inspect and manipulate its deep-embedded combinator tree, this transformation is possible.
However, this is not ideal from a performance perspective, since this transformation would have a runtime overhead -- because of this, \texttt{parsley-garnish} was conceptualised as a linter rather than part of \texttt{parsley} itself.

On the other hand, \texttt{parsley} Haskell and the future \texttt{meta-parsley} implementation in Scala would be able to implement a staged version of this transformation, eliminating this overhead.
This could therefore be future work for the \texttt{meta-parsley} project.

One could argue from a design perspective that the higher-level abstraction of the \scala{chain} combinators is a more desirable form to write parsers for left-associative operations, rather than a lower-level left-recursive grammar rule.
It could also be controversial for purists, in the sense that it obfuscates the \textsc{peg} semantics of the parser combinator library, allowing \textsc{cfg}-like parsers to be written directly.
These are design problems that could warrant further discussion in future work.

\subsection{Resugaring Parsers}
Significant improvements can be made in the resugaring of parser terms, since the current implementation is relatively naive: \cref{sec:eval-leftrec} shows where this sometimes fails.
The work by \textcite{pombrio_hygienic_2015} seems to be a promising approach to this problem, describing a resugaring approach that remembers and reflects the original style in which the expression was written.
This may have further ramifications, such as allowing the left-recursion transformation (or any future transformation rules) to show the user how it was achieved step-by-step, by resugaring the parser at each step of the transformation process.
This would further improve the pedagogical value of the \texttt{parsley-garnish} linter.

\subsection{Intermediate Expression \textsc{ast}}
The \scala{Expr} \textsc{ast} could be further improved in a number of ways:
\begin{itemize}
  \item Introducing a proper notion of $\eta$-reduction of \scala{Expr} terms could further simplify their final output. This is not well-defined on Scala, although a pseudo-$\eta$-reduction transformation would see lambda expressions being transformed to use placeholder syntax if they can.
  \item Implementing proper hygiene and well-scopedness in the \scala{Expr} \textsc{ast} would improve the reliability of the normalisation and partial evaluation techniques. Although the transformation of terms into expressions should be well-formed, there is no guarantee that the resulting expression is well-scoped. An approach similar to Squid's quasiquotes or Scala 3 macros would be beneficial for the expression architecture.
  \item Further improving the static inspectability of what are currently \scala{Translucent} terms could allow expressions to undergo real partial evaluation, rather than just normalisation. For example, if a fully closed term is reduced to \scala{Translucent(1 + 1)}, this could be evaluated to just \scala{2}. At the moment, this is not possible since \scala{Translucent} represents the furthest the term can be inspected.
\end{itemize}

\end{document}
